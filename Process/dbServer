sudo apt update
sudo apt install awscli -y

aws configure

# Set MySQL Pass:
sudo pkill mysqld
sudo systemctl stop mysql

sudo mkdir -p /var/run/mysqld
sudo chown mysql:mysql /var/run/mysqld
sudo chmod 755 /var/run/mysqld

sudo mysqld_safe --skip-grant-tables &
sleep 10

mysql -u root

FLUSH PRIVILEGES;
ALTER USER 'root'@'localhost' IDENTIFIED BY '8W!22)TlLd62';
FLUSH PRIVILEGES;
EXIT;

# Kill safe mode
sudo pkill mysqld
sleep 5

# Start normally
sudo systemctl start mysql

mkdir -p /home/ubuntu/backups


sudo vim /home/ubuntu/backup-db.sh

#!/bin/bash
# Database backup script - uploads to S3 in TWO regions then deletes local file

# Variables
DB_NAME="tailadmin_db"
DB_USER="tailadmin_user"
DB_PASS="TailAdminPass123!"
BACKUP_DIR="/home/ubuntu/backup"
DATE=$(date +%Y%m%d)
TIME=$(date +%H%M%S)
BACKUP_FILE="$BACKUP_DIR/${DB_NAME}-backup-${DATE}-${TIME}.sql.gz"
S3_BUCKET_PRIMARY="s3://db-backup-tailadmin"
S3_BUCKET_SECONDARY="s3://db-backup-tailadmin-dr"
REGION_PRIMARY="us-east-1"
REGION_SECONDARY="ap-south-1"

# Create backup directory if it doesn't exist
mkdir -p $BACKUP_DIR

echo "========================================="
echo "Starting backup at $(date)"
echo "========================================="

# Dump database and compress
echo "Creating database dump..."
mysqldump -u $DB_USER -p$DB_PASS --no-tablespaces $DB_NAME | gzip > $BACKUP_FILE

# Check if backup was successful
if [ $? -eq 0 ]; then
    SIZE=$(du -h $BACKUP_FILE | cut -f1)
    echo "✓ Database backup created: $BACKUP_FILE"
    echo "  Size: $SIZE"
    
    # Upload to PRIMARY region (N. Virginia)
    echo ""
    echo "Uploading to PRIMARY region ($REGION_PRIMARY)..."
    aws s3 cp $BACKUP_FILE $S3_BUCKET_PRIMARY/ --region $REGION_PRIMARY
    
    if [ $? -eq 0 ]; then
        echo "✓ Uploaded to PRIMARY: $S3_BUCKET_PRIMARY/$(basename $BACKUP_FILE)"
    else
        echo "✗ PRIMARY upload FAILED!"
        exit 1
    fi
    
    # Upload to SECONDARY region (Mumbai - DR)
    echo ""
    echo "Uploading to DR region ($REGION_SECONDARY)..."
    aws s3 cp $BACKUP_FILE $S3_BUCKET_SECONDARY/ --region $REGION_SECONDARY
    
    if [ $? -eq 0 ]; then
        echo "✓ Uploaded to DR: $S3_BUCKET_SECONDARY/$(basename $BACKUP_FILE)"
    else
        echo "✗ DR upload FAILED! (Primary backup is safe)"
        # Don't exit - primary backup succeeded
    fi
    
    # Delete local file after successful uploads
    echo ""
    rm -f $BACKUP_FILE
    
    if [ ! -f "$BACKUP_FILE" ]; then
        echo "✓ Local backup file deleted"
    else
        echo "✗ Warning: Failed to delete local file"
    fi
    
    echo ""
    echo "========================================="
    echo "Cross-region backup completed at $(date)"
    echo "  Primary: $REGION_PRIMARY (N. Virginia)"
    echo "  DR:      $REGION_SECONDARY (Mumbai)"
    echo "========================================="
    
else
    echo "✗ Database backup FAILED!"
    exit 1
fi



#### DR:

# Create DR bucket in Mumbai
aws s3 mb s3://db-backup-tailadmin-DR --region ap-south-1

# Verify
aws s3 ls --region ap-south-1 | grep tailadmin


vim /home/ubuntu/restore-db.sh

#!/bin/bash
# Database restore script - supports both regions

if [ -z "$1" ]; then
    echo "Usage: $0 <backup-filename> [region]"
    echo ""
    echo "Examples:"
    echo "  $0 tailadmin_db-backup-20260210-212000.sql.gz"
    echo "  $0 tailadmin_db-backup-20260210-212000.sql.gz dr"
    echo ""
    echo "Regions:"
    echo "  (default) - N. Virginia (us-east-1) - Primary"
    echo "  dr        - Mumbai (ap-south-1) - Disaster Recovery"
    exit 1
fi

BACKUP_FILENAME=$1
REGION=${2:-primary}
DB_NAME="tailadmin_db"
DB_USER="tailadmin_user"
DB_PASS="TailAdminPass123!"

# Determine S3 bucket based on region
if [ "$REGION" == "dr" ]; then
    S3_BUCKET="s3://db-backup-tailadmin-dr"
    AWS_REGION="ap-south-1"
    REGION_NAME="Mumbai (DR)"
else
    S3_BUCKET="s3://db-backup-tailadmin"
    AWS_REGION="us-east-1"
    REGION_NAME="N. Virginia (Primary)"
fi

S3_PATH="$S3_BUCKET/$BACKUP_FILENAME"
LOCAL_FILE="/tmp/$BACKUP_FILENAME"

echo "========================================="
echo "Database Restore"
echo "========================================="
echo "Backup file: $BACKUP_FILENAME"
echo "Region: $REGION_NAME ($AWS_REGION)"
echo "S3 path: $S3_PATH"
echo ""

# Download from S3
echo "Downloading from S3..."
aws s3 cp $S3_PATH $LOCAL_FILE --region $AWS_REGION

if [ $? -ne 0 ]; then
    echo "✗ Failed to download from S3"
    exit 1
fi

echo "✓ Downloaded successfully"
echo ""

# Confirm restore
echo "WARNING: This will OVERWRITE the current database!"
read -p "Continue? (yes/no): " CONFIRM

if [ "$CONFIRM" != "yes" ]; then
    echo "Restore cancelled"
    rm -f $LOCAL_FILE
    exit 0
fi

echo ""
echo "Restoring database..."

# Drop and recreate database
mysql -u $DB_USER -p$DB_PASS -e "DROP DATABASE IF EXISTS $DB_NAME; CREATE DATABASE $DB_NAME;"

# Restore
gunzip < $LOCAL_FILE | mysql -u $DB_USER -p$DB_PASS $DB_NAME

if [ $? -eq 0 ]; then
    echo "✓ Database restored successfully!"
    
    # Verify
    TABLES=$(mysql -u $DB_USER -p$DB_PASS -D $DB_NAME -e "SHOW TABLES;" | wc -l)
    echo "  Tables restored: $((TABLES - 1))"
else
    echo "✗ Database restore FAILED!"
    exit 1
fi

# Cleanup
rm -f $LOCAL_FILE
echo ""
echo "========================================="
echo "Restore completed at $(date)"
echo "========================================="



# Setup cronjob:
sudo mkdir -p /var/log
sudo touch /var/log/db-backup.log
sudo chown ubuntu:ubuntu /var/log/db-backup.log

crontab -e
